{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.25.1\n",
    "!pip install transformers\n",
    "!pip install datasets===2.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset and removing unnecessary columns\n",
    "dataset = load_dataset('amazon_us_reviews', 'Electronics_v1_00', split='train')\n",
    "dataset = dataset.remove_columns([x for x in dataset.features if x not in ['review_body', 'verified_purchase', 'review_headline', 'product_title', 'star_rating']])\n",
    "\n",
    "# Filtering the dataset and encoding the 'star_rating' column\n",
    "dataset = dataset.filter(lambda x: x['verified_purchase'] and len(x['review_body']) > 100).shuffle(42).select(range(100000))\n",
    "dataset = dataset.class_encode_column(\"star_rating\")\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42, stratify_by_column=\"star_rating\")\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the tokenizer\n",
    "MODEL_NAME = 't5-base'\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to preprocess the data\n",
    "def preprocess_data(examples):\n",
    "    examples['prompt'] = [f\"review: {example['product_title']}, {example['star_rating']} Stars!\" for example in examples]\n",
    "    examples['response'] = [f\"{example['review_headline']} {example['review_body']}\" for example in examples]\n",
    "\n",
    "    inputs = tokenizer(examples['prompt'], padding='max_length', truncation=True, max_length=128)\n",
    "    targets = tokenizer(examples['response'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "    # Set -100 at the padding positions of target tokens\n",
    "    target_input_ids = []\n",
    "    for ids in targets['input_ids']:\n",
    "        target_input_ids.append([id if id != tokenizer.pad_token_id else -100 for id in ids])\n",
    "\n",
    "    inputs.update({'labels': target_input_ids})\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the training and testing datasets\n",
    "train_dataset = train_dataset.map(preprocess_data, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning the T5 model\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "TRAINING_OUTPUT = \"./models/t5_fine_tuned_reviews\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=TRAINING_OUTPUT,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    save_strategy='epoch',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "trainer.save_model(TRAINING_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the fine-tuned model\n",
    "model = T5ForConditionalGeneration.from_pretrained(TRAINING_OUTPUT)\n",
    "\n",
    "# or get it directly trained from here:\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"TheFuzzyScientist/T5-base_Amazon-product-reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to generate reviews\n",
    "def generate_review(text):\n",
    "    inputs = tokenizer(\"review: \" + text, return_tensors='pt', max_length=512, padding='max_length', truncation=True)\n",
    "    outputs = model.generate(inputs['input_ids'], max_length=128, no_repeat_ngram_size=3, num_beams=6, early_stopping=True)\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating reviews for random products\n",
    "random_products = test_dataset.shuffle(42).select(range(10))['product_title']\n",
    "\n",
    "print(generate_review(random_products[0] + \", 3 Stars!\"))\n",
    "print(generate_review(random_products[1] + \", 5 Stars!\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
